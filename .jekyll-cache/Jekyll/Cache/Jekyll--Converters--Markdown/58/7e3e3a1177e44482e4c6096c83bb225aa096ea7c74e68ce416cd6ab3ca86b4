I"]"<p>This writeup is hosted at <a href="https://cal-cs184-student.github.io/sp22-project-webpages-sagnibak/project-1">https://cal-cs184-student.github.io/sp22-project-webpages-sagnibak/project-1</a>.</p>

<h2 id="part-1-rasterizing-single-color-triangles">Part 1: Rasterizing single-color triangles</h2>

<p>We first finding a bounding box by calculating the minimum and maximum
x and y coordinates. For each point, we determine whether it’s inside
or outside the triangle by testing the orientation using the dot
product between the normal vector to the line and the vector
containing the point and a vertex of the line. If we traverse the
points in a clockwise manner, all signs should be negative. In
contrast, if we traverse the points in a counterclockwise manner, all
signs should be positive. To handle cases where the point lies on the
edge of the triangle, we denote landing on a line as <code class="language-plaintext highlighter-rouge">MAYBE</code>. Then we
enumerate all possibilities combinations of <code class="language-plaintext highlighter-rouge">TRUE/FALSE/MAYBE</code>s that
imply landing on or inside the triangle (either 2 MAYBEs which means
it’s a corner, 1 <code class="language-plaintext highlighter-rouge">MAYBE</code> and two <code class="language-plaintext highlighter-rouge">FALSE</code>s, or 1 <code class="language-plaintext highlighter-rouge">MAYBE</code> and two
<code class="language-plaintext highlighter-rouge">TRUE</code>s). In the case the point is in the triangle, we update the
sample buffer with the color of the triangle.</p>

<p><img src="../proj1/task2_img/test4_16.png" alt="imag" /></p>
<h3 id="part-2-antialiasing-triangles">Part 2: Antialiasing triangles</h3>

<p>To properly antialias, we resized the sample buffer by <code class="language-plaintext highlighter-rouge">sqrt{sampling_rate}</code> in both height and width dimensions. To avoid any potential floating point issues, we opted to scale our triangle up and traverse through the triangle in whole increments as opposed to keeping the triangle the same size and incrementing the traversals in fractional amounts. In the event that the point lies inside the triangle, we update the <code class="language-plaintext highlighter-rouge">sample buffer</code> to the color. Then, to render the image at the original size, in <code class="language-plaintext highlighter-rouge">resolve_to_framebuffer</code>, we take the average of <code class="language-plaintext highlighter-rouge">sampling rate</code> number of samples (a square that corresponds to one pixel) and update the <code class="language-plaintext highlighter-rouge">rgb_framebuffer</code> (the actual image rendering). This antialiases the triangles by providing inbetween colors. This can be seen as applying a filter ovr a pixel getting closer and closer to the true average color of the pixel.</p>

<div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="../proj1/task2_img/task2_1.png" align="middle" width="400px" />
        <figcaption align="middle">Sample rate: 1.</figcaption>
      </td>
      <td>
        <img src="../proj1/task2_img/task2_4.png" align="middle" width="400px" />
        <figcaption align="middle">Sample rate: 4.</figcaption>
      </td>
       <td>
        <img src="../proj1/task2_img/task2_16.png" align="middle" width="400px" />
        <figcaption align="middle">Sample rate: 16.</figcaption>
      </td>
    </tr>
  </table>
</div>

<p>The difference between sample rate 1 and sample rate 16 can be seen very clearly in the very skinny triangle corner. As we take more samples we can better approximate the true color. When we don’t supersample, because the triangle is skinny, probabilistically supersampling will better approximate the pixel. However, in practice, there will be situations where it just so happens that the point you sample ends up being inside the triangle. This is why even when the sample rate is 16, the zoomed in image isn’t smooth.</p>
<h3 id="part-3-transforms">Part 3: Transforms</h3>

<p>For this, I was trying to get the robot’s right arm to wave. I accomplished this by rotating the arms.</p>

<p><img src="../proj1/task3_img/screenshot_2-16_15-50-48.png" alt="waving_robot" /></p>
<h2 id="task-4-barycentric-coordinates">Task 4: Barycentric Coordinates</h2>

<p>Barycentric coordinates can be seen as a way to figure out the
distance from the three vertices of a triangle, providing a coordinate
system that is relative to the triangle. They allow us to
smoothly blend attributes at the vertices of a triangle. The attribute
of interest for us is color in this part, but it can also be used to
help translate between image and texture coordinates by blending the
texture coordinates at each of the vertices.</p>

<p><img src="../proj1/task4_img/color_triangle.png" alt="triangle_with_colors_at_vertices" /></p>

<p>The figure above demonstrates the blending of colors using barycentric
coordinates. Each vertex is assigned a pure color: top is red $r$, left is
green $g$, and right is blue $b$. In order to color each of the other
pixels in the triangle, we first compute the barycentric coordinates
of the point using the formula presented in lecture. Let those
coordinates be $(\alpha, \beta, \gamma)$. Then, the color of the pixel
is given by $\alpha r + \beta g + \gamma b$. This provides an
intuitive visualization of barycentric coordinates.</p>

<p>Below is a screenshot of a color wheel made using triangles colored
using barycentric coordinates to determine the color of the pixels.</p>

<p><img src="../proj1/task4_img/color_wheel.png" alt="color_wheel" /></p>

<h2 id="pixel-sampling">Pixel Sampling</h2>

<p>Pixel sampling is the process of using the pixels of one image to
color the pixels of another image, by sampling the pixels of the
former image. In the process of texture mapping, there is an object
(like a triangle) which is being rasterized, and there is an image
known as the <em>texture</em> which provides the pixels that will be colored
onto the object. In order to find the color of a pixel in the
rasterized version of the object, the texture is sampled at a
specified location, either using <em>nearest</em> or <em>bilinear</em> sampling, and
then the sampled color is painted onto the rasterized pixel.</p>

<p>In order to do pixel sampling on a triangle, first we obtain the
barycentric coordinates of the pixel in the triangle, then we use the
barycentric coordinates to find the correct location to sample the
texture from a triangular region whose vertices are given to us.</p>

<p>In <strong>nearest sampling</strong>, the pixel in the texture nearest to the sampling
location is chosen, and its color is painted on the triangle pixel.</p>

<p>In <strong>bilinear sampling</strong>, a weighted average of the four texture
pixels surrounding the sampling location is calculated. The weighting
is based on the closeness of each texture pixel to the sampling
location. This weighted average color is painted on the triangle
pixel.</p>

<h3 id="comparison-of-bilinear-vs-nearest-pixel-sampling">Comparison of Bilinear vs. Nearest Pixel Sampling</h3>

<p>The four images below show a comparison of bilinear and nearest pixel
sampling. As we can see, nearest pixel sampling is more prone to
having rougher edges, and the colors seem somewhat noisier due to
sharp transitions. On the other hand, bilinear sampling creates
smoother gradients of colors, and also makes edges appear smoother
even at lower sampling rates.</p>

<p><img src="../proj1/task5_img/nearest_1pp.png" alt="" />
<img src="../proj1/task5_img/bilinear_1pp.png" alt="" />
<img src="../proj1/task5_img/nearest_16pp.png" alt="" />
<img src="../proj1/task5_img/bilinear_16pp.png" alt="" /></p>

<p>We believe that there will be a large difference between the
performance of these two sampling algorithms when there is a large
degree of texture minification, where nearest pixel sampling will be
prone to aliasing more than bilinear sampling, since bilinear sampling
is equivalent to low-pass filtering after taking extra samples, which
leads to antialiasing.</p>

<h2 id="part-6-level-sampling-for-texture-mapping">Part 6: Level sampling for texture mapping</h2>

<p>We level sample to figure out the correct resolution of textures to
use in our image. To write this helper function, we first calculate
($\frac{\partial u}{\partial x}, \frac{\partial u}{\partial x})$ and
$(\frac{\partial u}{\partial x}, \frac{\partial u}{\partial x})$ by
looking at the barycentric coordinates of adjacent points $P(x,y),
X(x+1, y), \text{ and } Y(x, y+1).$ After calculating the
differentials $PX = P - X$ and $PY = P + Y$, we can determine the
level by taking $log_2 max {|PX|, |PY|}$.</p>

<p>Tradeoffs between speed, memory usage, antialiasing</p>
:ET